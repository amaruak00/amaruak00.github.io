---
layout: post
title: ADP 실기 27회 복기
tags: [ADP, Python]
---

(기계학습 50점)

> 데이터는 [캐글 데이터](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud)에서 일부 정제한 데이터가 사용됨. 해당 데이터에서 `V1~V17` 컬럼만 사용(총 컬럼 `20`개). 약 1,193건의 데이터였음


1. 신용카드 이상탐지 데이터 **[지도학습, 이상탐지]**

   - 1-1 EDA 데이터 탐색

     ```python
     ### 기본적인 EDA 수행함. 
     ### - 결측치 여부, 
     ### - 데이터 타입 설명, 
     ### - 종속변수에 각 독립변수들 간의 관계 막대그래프로 시각화.
     ```

   - 1-2 변수간 상관관계를 시각화하고 전처리가 필요함을 설명하라.

     ```python
     ### pandas의 corr()를 구한 후 
     ### heatmap() 시각화한 후 설명 진행했다. 

     ### 결국 특정 변수들 간 상관관계가 높은 변수들이 더러 있었고
     ### (해당 변수들 쌍을 다 적었음),
     ### 원래라면 전처리할 때 다중공선성 방지를 위해 이런 변수들은 정리해줘야 하는데
     ### 컬럼명이 익명이라(V1~V17) 명시적으로 컬럼이 뭘 나타내는지를 추정할 수 없고, 
     ### 컬럼수가 많기 때문에 이런 상관성을 확인만 한 후 차원축소 등의 방법을 사용해야 한다고 적었음
     ```

2. 차원축소 관련

   - 2-1. 차원축소의 종류와 장/단점

     ```python
     ### PCA, LDA, tSNE 등을 적었고 
     ### 이 부분은 책을 참조해서 적었다.
     ```

   - 2-2. 추천한 한 가지를 실제로 수행하고 선택한 이유 설명

     ```python
     ### LDA는 Binary Classification에서는 독립변수를 1개로 축소하는데
     ### 19개를 1개로 줄이면 손실되는 데이터가 너무 많을 것 같아 버렸고
     ### 데이터 손실률이 적어 분류모델 전처리에 가장 많이 쓰이는 PCA를 선택했다.

     ### PCA의 적정한 컴포넌트 수를 찾기 위해 
     ### 3~5개의 PCA를 만든 후 scree plot를 각각 그려보았고, 그 결과 3이 가장 적정함을 보였다.
     ```
   

3. 오버샘플링/언더샘플링 관련

   - 3-1. 장/단점 기술하고, 한 가지 추천

     ```python
     ### 책에 관련 문제에 대한 모범답안이 있어 최대한 비슷하게 적었다.
     ### 결국 오버샘플링을 추천했다. 
     ### 종속변수 값이 unbalance해서 언더샘플링할 경우 데이터가 1,000개 정도 날아가기 때문.
     ```

   - 3-2. 추천한 한 가지를 실제로 수행하고 선택한 이유 설명

     ```python
     ### 오버샘플링 중 SMOTE를 사용했는데, 
     ###이유는 랜덤오버샘플링을 사용하기엔 y=1인 데이터 수가 19개? 정도밖에 없어서
     ### 19개를 복사하는건 의미가 없어서 데이터를 근사하게 만드는 SMOTE가 이 경우 더 유용하다고 판단했다고 적었다.

     ### SMOTE한 후 샘플링 이전 데이터와 이후 데이터에 대한 scatter plot을 그려서
     ### 값이 적절히 샘플링되었음을 시각화했다.
     ```

   - 3-3. 현재까지 전처리한 데이터를 통해 모델 수행 후 결과 분석

     ```python
     ### 분류모델의 국밥같은 존재인 sklearn의 
     ### Logisticregression과 RandomForestClassifier를 선정
     ### 모델만들고, 여태까지 전처리한 데이터 넣고 돌렸다.

     ### 돌린 후 분류모델의 측정지표들인 
     ### confusion matrix, f1score, auc, roc_curve 등을 구하고
     ### roc curve에 대한 그래프 시각화를 두 모델 각각 진행했다. 
     ```


4. 이상탐지 모델 관련
   - 4-1 이상탐지 모델 2가지 이상 기술, 장/단점 설명

     ```python
     ### 여기서는 잘 몰라서 보통 분류모델을 많이 쓰며
     ### 위에서 안쓴 모델은 SVC나 KNN이 있다고 적었다.
     
     ### sklearn의 isolation forest나 DBSCAN 같은 알고리즘이 이상탐지를 위한 모델이라고 하더라..
     ### 아마 여기서 감점되었을 듯
     ```

   - 4-2 `2번`에서 만든 데이터로 한 가지 이상탐지 모델을 구현하고, `3번`에서 만든 모델과 비교

     ```python
     ### 여기서 KNN모델을 만들겄고, 3번과 같이 모델지표측정하고 시각화했다.
     ### 이후 나온 정확도나 auc 값 등으로 앞서 만든 모델과 비교했다.
     ```

   - 4-3 데이터분석과 관점에서 `3번`에서 만든 모델과 `4번`에서 만든 모델 설명

     ```python
     ### 3번에서 만든 두 모델은 정확도 99% 나왔었고 4번의 KNN은 95%가 나왔었다. 
     ### 근데 Confusion Matrix 확인해보니 3번 모델은 False Negative가 각각 1개씩 있었다. KNN은 0개였다. 
     ### 여기에 착안해 이상탐지 모델은 정확도도 물론 중요하지만 False Negative 즉
     ### 사기 건수를 사기 건수가 아니라고 할 경우가 매우 치명적이므로 
     ### 얼핏 정확도만 봤을 때 99%의 모델을 추천하는 것이아닌 
     ### FN이 없는 모델을 추천하는 것이 분석가의 올바른 관점이라고 적었다. 
     ```


(통계분석 50점)

1. 2년 전 10만, 1년 전 15만, 올해 25만이면 연 평균 생산량은 몇 %인가?
   
   ```python
   #기하평균 사용
   f'{round(((15/10 * 25/15)**0.5 -1) * 100, 2)}%'
   ```

2. 광고시간에 대한 90% 신뢰구간 구하기, 8개 광고에 대한 평균, 분산이 나왔음.

   ```python
    # 정규분포를 가정하며, 집계한 광고 수가 30개 미만이므로 t검정을 사용한다.
    from scipy import stats 
    stats.t.interval(alpha=0.9, loc=[평균], scale=np.sqrt([분산]/[광고수]), df=[광고수]-1)
   ```

3. 15개 강의 상류와 하류의 어류다양성 점수. 상류-하류는 독립 아닌 종속
   - 3-1. 귀무가설과 대립가설 설정하라.

   ```python
    ### H0: 상류-하류간 어류다양성 점수 상관 없다.
    ### H1: 상관 있다.
   ```

   - 3-2. 통계량을 구하고, 대립가설 채택 여부를 기술하라.

   ```python
   ### t검정을 사용한다고 생각함.
   ### 상류/하류 간 독립이 아니라고 했으므로 
   ### 독립표본 검정(쌍검정)이 아닌 대응표본 검정을 실행해야 한다고 생각했다.

   ### 먼저 상류와 하류 데이터에 대한 각각의 정규성 검정을 했다.
   from scipy import stats
   stats.shapiro(df.up), stats.shapiro(df.down)

   ### 이때 두 데이터 중 하나가 정규성을 만족 못하여 
   ### stats.ttest_rel을 쓰지 못하고, 윌콕슨 검정을 시행했다.
   stats.wilcoxon(df.up, df.down) 

   ### 시행 결과 p값이 0.05 미만으로 나와 귀무가설을 기각했다. 
   ### 즉, 상류-하류간 어류다양성 점수에 유의미한 차이가 있었다.

   ```


4. 백분위 회귀
   - 4-1. 주어진 데이터에 대해 백분위 50%로 잡고 백분위 회귀 모델을 구현하고 계수들에 대해 설명하라.

   ```python
    ### 이건.. 몰라서 OLS 사용하고 열심히 계수를 설명했다.
    ### 나중에 물어보니 statsmodels.formula.api.quantreg를 쓰면 된다고 한다.

    import statsmodels.formula.api as smf 

    model = smf.quantreg('y~x', data) 
    result = model.fit(q=0.5)
    print(result.summary())
   ```

   - 4-2. 구현한 모델에 특정 값을 넣고 값에 대해 설명하라.

   ```python
   ### 위에서 구현한 모델에 model.predict() 써서 값 적으면 됐다.
   ```

5. 지하철 호선과 월별, 승객 수 간 상관관계가 있는지 확인(Type III Anova 사용)

   - 5-1. 귀무가설과 대립가설 설정하라.
   ```python 
   ### H0. 상관관계가 없다. 
   ### H1. 상관관계가 있다.
   ```

   - 5-2 통계량을 구하고, 대립가설 채택 여부를 기술하라.

   ```python 
   ### 이원배치 분산분석 문제였다! 난 이걸 잊고 변수 간 계수 문제로 착각했다. 
   ### ANOVA까지 가지 않고 모델만 만들고 모델을 설명해버렸다. 
   ### type 3도 보고는 멘붕이였는데 anova_lm typ가 3까지 있더라.. 왜 2까지 있는줄 알았지

   import statsmodels.formula.api as smf 

   model = smf.ols('y~line+month+line:month', df)
   print(model.summary())

   print(stats.anova_lm(model, typ=3))
   ### 이후 나온 계수에 대해 설명하면 된다.
   ```
